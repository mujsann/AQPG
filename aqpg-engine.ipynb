{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"cebdf444-2099-4ffa-bacd-71ca26f4eadf","_cell_guid":"e2bd9f59-352d-4085-a9cd-c5568d1d5d53","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#input story here\ndoc =\"\"\"\"\"\"\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input entities here\nEntities = \"\"\"\"\"\"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for e in Entities:\n    if Entities[e].lower()== 'player':\n        player_name = e.lower()\n        break;\nstoryname = ''","metadata":{"execution":{"iopub.status.busy":"2021-05-24T01:31:11.643787Z","iopub.execute_input":"2021-05-24T01:31:11.644182Z","iopub.status.idle":"2021-05-24T01:31:11.648682Z","shell.execute_reply.started":"2021-05-24T01:31:11.644149Z","shell.execute_reply":"2021-05-24T01:31:11.647895Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"##segmentation module\nstory = doc.lower()\nsegments = []\nlocations = []\nfor entity in Entities:\n    if Entities[entity] == 'location':\n        locations.append(entity.lower())\n\nlocations_no = {}\n\n# Get number of every location\nfor location in locations:\n    loc_no = story.find(location)\n    if loc_no is not  -1:\n        locations_no[location] = loc_no\n\n\n\n# sort location by number\nsorted_locations = []\nsorted_loc = {k: v for k, v in sorted(locations_no.items(), key=lambda item: item[1])}\n\nfor loc in sorted_loc:\n    sorted_locations.append(loc)\n# print(sorted_locations)\n\n# Get first segment #\nloc1 = story.find(location) + len(location)+1\nloc2 = story.find(sorted_locations[1])\n\n\nlast_stop  = story[:loc2][::-1].find(\".\")   # last stop before location2\nfirst_boundary = loc2 - last_stop+1\n\nstory_after_loc1 = story[first_boundary:]\n\nsegment_1 = story[:first_boundary]\nsegments.append(segment_1)\n# print(\"segment\"+\"0\", \":\", segment_1)\n\nmonitor = 1\nseg_length = len(segment_1)\n\n#Get for segment two then replicate for others\nif monitor > 0:\n\n    #last and next location\n    loc1 = story_after_loc1.find(sorted_locations[1])+len(sorted_locations[1])+1\n    loc2 = story_after_loc1.find(sorted_locations[2])\n\n\n    # inverse\n    rev_story = story_after_loc1[:loc2][::-1]\n    nxt_stop = rev_story.find(\".\")\n  \n    \n    # reverse inverse\n    segment = rev_story[nxt_stop:][::-1]\n    seg_length = seg_length + len(segment)\n    segments.append(segment)\n#     print(\"segment\"+\"1\"+ \":\"+ segment , \"\\n\")\n\n\n    story_after_loc1 = story[seg_length:]\n    # print(story_after_loc1)\n\n#Get segments from three to four\n    #to check if a location has gone with the initial location's sentence\n    #check if which of the locations is present in the sentence and remove from the list\nlocs_length = len(sorted_locations[2:])\nfor a, location in enumerate(sorted_locations[2:], 2):\n            #if location is not the last location\n\n    if a < locs_length+1:\n                # this and next location\n        loc1 = story_after_loc1.find(sorted_locations[a]) + len(sorted_locations[a]) + 1\n        loc2 = story_after_loc1.find(sorted_locations[a + 1])\n\n\n        # invert\n        rev_story = story_after_loc1[:loc2][::-1]\n        nxt_stop = rev_story.find(\".\")\n\n        # reverse the inverse\n        segment = rev_story[nxt_stop:][::-1]\n        seg_length = seg_length + len(segment)\n#         print(\"segment\" + str(a)+ \":\"+ segment, \"\\n\")\n        segments.append(segment)\n\n        story_after_loc1 = story[seg_length:]\n\n    else:\n        segments.append(story_after_loc1)\n#         print(\"segment\" + str(a)+ \":\"+ story_after_loc1, \"\\n\")\n\n\n\n\nsegments = [segment for segment in segments if len(segment)>1]\nfor i, segment in enumerate(segments):\n    print(str(i)+\":\"+segment)","metadata":{"_uuid":"6496bcea-97aa-4748-ae67-8a02acdd253c","_cell_guid":"96669b4d-5c41-4797-86b9-1a39c4710ba9","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import spacy\nnlp = spacy.load(\"en_core_web_sm\")\n\n#load segments\nall_segments = [nlp(segment) for segment in segments ]","metadata":{"_uuid":"373feb74-6d98-4995-b9c2-d8275dc62c19","_cell_guid":"764f4fd2-a070-49e5-95de-d467e8297e08","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# random cost\nimport random\ndef random_cost():\n    return random.randint(1,4)\nprint(random_cost())","metadata":{"_uuid":"744c552a-4296-4672-9e4c-dc872d0a8158","_cell_guid":"3caa3b62-d8fa-4e76-9b3a-b38ffb259ab3","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##helpers\n# lemmatizes\ndef lemmat(action):\n    action  = nlp(action)\n    for token in action:\n        return token.lemma_\n        break;\nspace = ' '\n\n#turns entities into predicate labels\ndef label(entity):\n    return \"?\"+str(entity)[:3]\n\n\n#remove duplicate from list\ndef unduplicate(arr):\n    arr  = list(dict.fromkeys(arr))\n    return arr\n\n#get past\nverbs_data = pd.read_csv(\"../input/english-verbs-and-their-tenses/verb.csv\")\nverbs= verbs_data.copy()\nverbs = verbs[['convolute', 'convoluted']]\ndef get_past(action):\n    act= lemmat(action)\n    verb  = verbs.loc[verbs['convolute'] == act]\n    \n    try:\n        return verb.convoluted.values[0]\n    except:\n        return action","metadata":{"_uuid":"4409e9ea-c195-4409-bda3-6866c344242b","_cell_guid":"af8c08e8-b941-4765-9e0e-1e2da1caa3d9","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#function to check if word is among the entities\ndef isEntity(word):\n    re = False\n    for entity in Entities:\n        if entity is str(word):\n            re  = True\n            break; \n    return re\n\n#returns entity label\ndef ent_value(ent):\n    ent = str(ent).lower()\n    value = None\n    for entity in Entities:\n        if entity.lower() == ent:\n            value = Entities[entity]\n            break\n    return value","metadata":{"_uuid":"32bfb728-44d8-4c47-92b4-debf71be23f4","_cell_guid":"2f3f0207-b67c-4795-a69b-e97d6d16c759","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#import and clean story\nimport spacy\nfrom spacy.symbols import nsubj, VERB, NOUN\nfrom spacy import displacy\nnlp = spacy.load(\"en_core_web_lg\")\nstory = nlp(doc.lower())","metadata":{"_uuid":"7221b6c3-f65d-4ea1-98e8-03d681383dd0","_cell_guid":"029047bc-ee12-496a-8e6d-535649946b28","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#returns effects\ndef dob_effects(subsegment):\n    doc = nlp(subsegment[1])\n    doc_param = subsegment[2]\n    doc_action = subsegment[0]\n    for token in doc:\n        if token.dep_ is \"nsubj\"and token.text == player_name and token.head.pos is VERB :\n            action = token.head\n            child = [child for child in action.children if child.dep_ == 'dobj']\n            if child:\n                return (get_past(str(action))+ space+ label(ent_value(child[0].lower())))\n            else:\n                return (get_past(str(doc_action)))","metadata":{"_uuid":"301ff015-ef5c-4c86-8b55-f5635957a497","_cell_guid":"ffb59930-8ccc-40ee-aa73-051cf7558d4a","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# save the segment number and the pobjs\n#returns effect of subseg and count of effects in the sub_seg\ndef get_dob_effect(subsegment):\n#     doc = doc.lower()\n    doc = nlp(subsegment[1])\n\n    pobjs = []\n    act_pobjs = []\n    for token in doc:\n        if token.dep_ is 'pobj' or token.dep_ is 'dobj' or token.dep_ is 'nsubj':\n            pobjs.append([token, token.i])\n        \n    for token in doc:\n        if token.dep_ is \"nsubj\"and token.text == player_name and token.head.pos is VERB :\n            action = token.head\n            index = action.i\n            get_pobj = [[action, pobj[0]] for pobj in pobjs if index<pobj[1]]\n            \n            if get_pobj:\n                act_pobjs.append(get_pobj[0])\n            \n    if act_pobjs:\n        for act in act_pobjs:\n            if str(subsegment[0]) == str(act[0]):\n                eff = act \n                print(eff)\n\n        effect = get_past(str(eff[0]))+ space+ label(ent_value(eff[1]))\n        return(effect)\n    return (\"none\")\n#    print(effect)\n    \n# get_dob_effect(subsegments[1])","metadata":{"_uuid":"552de05e-5402-4b3d-bb51-bbaed5a4ebad","_cell_guid":"a58038b4-5290-45d1-b3b7-fd071a360afe","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_obj(subsegment):\n#     doc = doc.lower()\n    doc = nlp(subsegment[1])\n\n    pobjs = []\n    act_pobjs = []\n    for token in doc:\n        if token.dep_ is 'pobj' or token.dep_ is 'dobj' or token.dep_ is 'nsubj':\n            pobjs.append([token, token.i])\n        \n    for token in doc:\n        if token.dep_ is \"nsubj\"and token.text == player_name and token.head.pos is VERB :\n            action = token.head\n            index = action.i\n            get_pobj = [[action, pobj[0]] for pobj in pobjs if index<pobj[1]]\n            \n            if get_pobj:\n                act_pobjs.append(get_pobj[0])\n            \n    if act_pobjs:\n        for act in act_pobjs:\n            if str(subsegment[0]) == str(act[0]):\n                eff = act \n            \n\n        objct = eff[1]\n        return(objct)\n    return (\"none\")\n#    print(effect)\n    \n# get_dob_effect(subsegments[1])","metadata":{"_uuid":"2649dad3-5503-49ad-a1aa-7ddb944baf15","_cell_guid":"80b05353-9554-495d-8d79-99a1e59d32ec","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# #explicit effect\n# Explicit = ['induce', 'give rise', 'stir up', 'create', 'start', 'launch', 'produce', 'generate', 'effect', 'arouse', 'provoke', 'elicit', 'bring about','lead',\n# 'lead to', 'trigger', 'derive', 'associate', 'relate', 'link', 'stem from', 'originate', 'bring forth', 'lead up', 'trigger off', 'bring on', 'result from',\n#             'set up', 'commence', \"set off\", 'set in motion', 'bring on', 'conduce to', 'educe', 'originate in', 'lead off', 'spark', 'spark off', 'evoke', \"link up\", \"activate\", 'actuate'\n#            \"put forward\", \"give birth to\", \"fire up\", \"unlease\"]\n\n# def get_ex_effect(subs,seg):\n#     for verb in Explicit:\n#         a = seg.find(verb)\n#         if(a>=0):\n#             return (get_past(lemmat(verb)))\n#         else:\n#             return None","metadata":{"_uuid":"8cc01d74-ed1b-4629-aa7a-5b7a1a2d10ac","_cell_guid":"e7ce67a9-edf6-4d03-8cf9-188c54b571ad","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# #implicit Effects\n# from nltk.corpus import wordnet as wn\n# def imp_effects(subsegment):\n#     action = subsegment[0]\n#     for synset in wn.synsets(action):\n#         a = synset.definition()\n#         if(a.find('cause to')>=0):\n#             return nlp(a)[2]\n        \n# imp_effects([\"kill\"])","metadata":{"_uuid":"b6a8ef21-050f-4ab9-b3a0-ce074fed66cf","_cell_guid":"8e85d546-7c44-4f1f-ac92-733b93256107","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#subsegmentation module\n#subsegmentation module\n\nall_subsegments = []\nall_actions = {}\nall_actionss = [] \nlemma_actionss = []\nobjects = []\nfor count, segment in enumerate(segments):\n    segment = nlp(segment)\n    actions = []\n    \n    action = ''\n    \n    for token in segment:\n        if token.dep_ is \"nsubj\"and token.text == player_name and token.head.pos is VERB:\n            act = [token.head.text, token.i]\n            actions.append(act)\n\n            all_actions[count] = actions \n            all_actionss.append([count, token.head.text])\n            \n            action = token.head.text\n            act_obj = get_obj([action,str(segment)])\n            objects.append(act_obj)\n#             print(act_obj)\n        \nfor i, actions in enumerate(all_actionss):\n    action = actions[1] #current action\n    act_segment = str(all_segments[actions[0]]) #segment containing the action\n    if(i<len(all_actionss)-1):\n        nxtaction = all_actionss[i+1] #next action\n        #find location of the current action\n        act_loc = act_segment.find(action)\n        #reverse the segment\n        begtoact = act_segment[:act_loc]\n        #find where the player is mentioned last between the beginnig and the action\n        r_player = player_name[::-1]\n        player_loc = len(begtoact)-begtoact[::-1].find(r_player)-len(player_name) \n#       the last name where the player is mentioned before the action\n        if(act_segment[act_loc:].find('.')>-1):\n            nxt_stop = len(act_segment[:act_loc]) + act_segment[act_loc:].find('.')+1\n            print(i,act_segment[player_loc:nxt_stop], \"\\n\")\n            all_subsegments.append(act_segment[player_loc:nxt_stop])\n        else:\n            print(i, act_segment[player_loc:], \"\\n\")\n            all_subsegments.append(act_segment[player_loc:])\n\n            \n        \n    else: \n        act_loc = act_segment.find(action)\n        \n        begtoact = act_segment[:act_loc]\n        #find where the player is mentioned last between the beginnig and the action\n        r_player = player_name[::-1]\n        player_loc = len(begtoact)-begtoact[::-1].find(r_player)-len(player_name) \n#         print(act_segment[player_loc:])\n#       the last name where the player is mentioned before the action\n#         print(len(act_segment),len(act_segment[act_loc:]) )\n        if(act_segment[act_loc:].find('.')>-1):\n            nxt_stop = len(act_segment[:act_loc]) + act_segment[act_loc:].find('.')+1\n            print(i, act_segment[player_loc:nxt_stop], \"\\n\")\n            all_subsegments.append(act_segment[player_loc:nxt_stop])\n        else:\n            print(i, act_segment[player_loc:], \"\\n\")\n            all_subsegments.append(act_segment[player_loc:])","metadata":{"_uuid":"30d1da78-86d2-43ac-826f-812e9501b0ac","_cell_guid":"4260f09a-28c1-498d-bed8-0905eb0a2e92","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n#get all player's actions\nplayer_actions = []\nfor token in story:\n    if token.dep_ is \"nsubj\"and token.text == player_name and token.head.pos is VERB:\n        player_actions.append(token.head.text)\n#         print(token.text, token.pos_, token.tag_, token.dep_, token.head.text, token.i)","metadata":{"_uuid":"c625ed20-6392-47d9-84a9-6bc14ce123f0","_cell_guid":"ceedf832-e946-4183-b290-b497ab06d911","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Extraction from subsegmentation\n#input story\n#output subsegments = [action, subsegment, entities, parameters]\n# sents = [sent.text for sent in story.sents]\nsents = all_subsegments\n#take sentences where the player is performing actions\n#save the action, the sentence, the entities and their parameters \nsubsegments= []\nfor sent in all_subsegments:\n    for token in nlp(sent):\n        if token.dep_ is \"nsubj\" and token.text == player_name and token.head.pos is VERB :\n            #get parameters and entity preonditions\n            param_ents= []\n            r_entities = []\n            params = []\n            ent_preconds = []\n            for entity in Entities:\n                e = str(sent).find(entity.lower())\n                if e >-1:\n                    param_ents.append(entity)\n                    r_entities.append(Entities[entity])\n                    params.append(label(Entities[entity]))\n                    ent_preconds.append(Entities[entity]+ space + label(Entities[entity]))\n            s = [token.head, sent, param_ents,r_entities, params, ent_preconds]\n            subsegments.append(s)\n            \n# for i, subsegment in enumerate (subsegments):\n#     effects = dob_effects(subsegment)\n#     subsegments[i].append(effects) \nfor s in subsegments:\n    if get_dob_effect(s):\n        s.insert(2,get_dob_effect(s) )\n    \n    \nfor s in subsegments:\n    print(s, \"\\n\", \"\\n\")\nlen(subsegments)","metadata":{"_uuid":"b7dc8b69-23c8-48b8-af84-5733f596ffe7","_cell_guid":"e71429f7-3053-412d-95ea-f406f22bcbc5","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n#check the verb\n#check if the former effect has ?non, if yes, replace with one of the ones here\n#also check if the ?xxx is one of the parameters\nplayer_actions = []\npred_entities= []# entities that will be used as predicates\nacts_params = []\nfor i, subseg in enumerate(sents):\n    subseg  = nlp(subseg)\n    for token in subseg:\n        if token.dep_ is \"nsubj\"and token.text == player_name and token.head.pos is VERB :\n            action = token.head\n            a = [child for child in action.children if child.dep_ is \"prep\"]\n            if(len(a)):\n                parent  = a[0]\n                b = [chil for chil in parent.children if chil.dep_ == 'pobj']\n                if len(b):\n                    acts_params.append([player_name, str(token.head), b[0], i,])\n                    if ent_value(b[0]):\n                        e = str(ent_value(b[0]))\n                        pred_entities.append([get_past(str(token.head)), label(e)])\n                        \n                        \n            c = [child for child in action.children if child.dep_ == 'dobj']\n            if(len(c) and ent_value(c[0])):\n                acts_params.append([player_name, str(token.head), c[0],i,])\n                player_actions.append(str(token.head))\n                if ent_value(c):\n                    e = str(ent_value(c[0]))\n                    pred_entities.append([get_past(str(token.head)), label(e)])\n                    \n                    \n        if token.dep_ == \"advcl\":\n             for child in token.children:\n                for entity in Entities:\n                    if entity == str(child):\n                        if(ent_value(entity)):\n                            acts_params.append([player_name, str(token), entity, i])\n                            player_actions.append(str(token))\n                            if ent_value(entity):\n                                e = str(ent_value(entity))\n                                pred_entities.append([get_past(token.text), label(e)])\n                            break;","metadata":{"_uuid":"6be554b5-9c89-494d-8d02-1d10146a9998","_cell_guid":"2ed235e2-a67d-404a-8e73-b118e28f08d2","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndef get_preconditions(precs):\n    preconditions = \"\"\n    pars = {}\n    for p in precs:\n        param = p[p.find(' '):]\n        b4_param=p[:p.find(' ')]\n        if param in pars:\n            pars[param]+=1\n            preconditions+= \"(\"+ b4_param+ param +str(pars[param]) + \")\"+ space\n        else:\n            pars[param]= 0\n#             print(pars)\n            preconditions+= \"(\"+b4_param+ param+ \")\"+ space\n    return(preconditions)\n\ndef get_parameters(params): #adds one to param count\n    parameters = \"(\"\n    pars = {}\n    for p in params:\n        if p in pars:\n            pars[p]+=1\n            parameters+=  p +str(pars[p]) + space\n        else:\n            pars[p]= 0\n            parameters+=  p + space\n   \n       \n    return(parameters+  \" \")\n\ndef alt_effects(eff, params): #eff is the segment's direct effect e.g read ?inf\n    for alt in pred_entities:\n        chosen_alt = None\n        if eff.find(str(alt[0])) >-1: #find the action in the direct effect\n            chosen_alt = alt\n            if(chosen_alt != None): #check if the param is part of the params in the same action\n                params = str(\" \".join(params))\n#                 print(\"this is params\", params,chosen_alt[1] )\n                if(params.find(chosen_alt[1])>-1):\n                    effect = \"(\" + chosen_alt[0] + space + chosen_alt[1] + \")\"\n                    return effect\n            \n        \n    return None\nstates = []\ndef get_effects(eff, params):\n    a = eff.lower().find(\"?pla\")\n    b = eff.lower().find(\"?non\")\n    c = eff.lower().find(\"none\")\n# if it does search the alternative effects . \n    if a>-1 or b>-1 or c>-1:\n        effect = alt_effects(eff, params)\n        #save to states\n        states.append(effect)\n        return effect\n        \n    effect = \"(\" + str(eff) + \")\"\n    states.append(effect)\n    return effect \n        \ndef get_operators(subsegments):\n    operators = \"(:functions\" +\"\\n\"+\"(total-cost))\\n \\n\"\n    for segment in subsegments:\n        a = get_effects(segment[2], get_parameters(segment[-2]))\n        if(a != None):\n            operators+= (\"(:action \"+lemmat(str(segment[0]))+ \"\\n  \" +\n                   \":parameters \" + get_parameters(segment[-2])+ \")\"+ \"\\n  \"+ \n                   \":precondition (and \" + get_preconditions(segment[-1])  +\")\"+\"\\n\"+ \n                    \":effect (and \"+ get_effects(segment[2],segment[-2]) +\" (increase (total-cost) \" + str(random_cost()) +\")))\"+\"\\n\"\n                    )+\"\\n\"\n    \n    return operators\nprint(get_operators(subsegments))","metadata":{"_uuid":"bb6457f6-7caa-41ad-9612-8e50c39fd02c","_cell_guid":"63d7a425-c637-4a16-92c6-40bec3f93d75","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# predicates\ndef param_preds(subsegments):\n    predicates = []\n    for segment in subsegments:\n        preds = segment[-1]\n        for pred in preds:\n            predicates.append(\"(\"+pred+\")\")\n    predicates = unduplicate(predicates)\n    return predicates\n    \n#get state preds from al efects\nstate_preds = unduplicate(states)\nstate_preds.remove(None)\n# print(state_preds)\n# param_preds(subsegments)\nall_preds = param_preds(subsegments) + state_preds\nall_preds","metadata":{"_uuid":"dad03d01-08ca-4461-897a-1b7670e2c396","_cell_guid":"e9ca71fd-d2ca-4dbc-a650-c0868022ffd3","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_predicates(preds):\n    predicates = \"\"\n    for pred in preds:\n        predicates+=pred+\"\\n\"\n        \n    return( \"(define (domain \" +storyname+\"land)\" +\"\\n\"+\n            \"(:requirements :action-costs)\" + \"\\n\"+\n            \"(:predicates\"+ \"\\n\"+\n             predicates+\")\" )","metadata":{"_uuid":"dfbc9e1c-dd19-46d0-b99a-9e85d7b74d34","_cell_guid":"e74234b9-7e60-42e7-85ec-1dd8db4a86d9","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# => change entities here, puth hyphen for the ones that have space\ndef init_objects():\n    initial_objects = []\n    objects = \"\"\n    for entity in Entities:\n        if entity.lower() != player_name:\n            initial_objects.append(entity.replace(\" \",\"-\").lower())\n    initial_objects = unduplicate(initial_objects)\n    for obj in initial_objects:\n        objects+= obj+\" \"\n    return (\"(define (problem \"+player_name+\")\"+\"\\n\"+\n            \"(:domain \"+storyname+\"land)\"+\"\\n\"+\n            \"(:objects you \"+objects+\") \\n\")\n\n\ndef initial_state():\n    init_state = \"\"\n    inits =[]\n    for entity in Entities:\n        if entity.lower() != player_name: \n            inits.append(\"(\"+ Entities[entity].replace(\" \",\"-\").lower()  + space +entity.replace(\" \",\"-\").lower() + \")\")\n    inits = unduplicate(inits)\n    for init in inits:\n        init_state+= init+\"\\n\"\n    return (\"(:init (player you) \\n\"+\"(= (total-cost) 0) \\n\"+init_state+\")\\n\")\n\ngoal_objects =[] \nfor entity in Entities:\n    goal_objects.append([entity,label(Entities[entity]) ])\nprint(init_objects())\nprint(initial_state())\nprint(goal_objects)","metadata":{"_uuid":"0dab3ec8-cc8d-44c7-9c04-d76ab55977bf","_cell_guid":"b66710cf-6f9f-452c-b92f-524694dad3cb","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#get goal object\ndef gobj():\n    random.shuffle(goal_objects)\n    return (goal_objects)\n\ngoals = []\nfor i in range(1, 6):\n    no = random.randint(0,len(state_preds)-1)\n    sp = state_preds[no]\n    labl = sp[sp.find(\" \"):-1]\n    act = sp[1:sp.find(\"?\")-1]\n    for s in gobj():\n        new_s = \" \".join(s)\n        s_labl = new_s[new_s.find(\"?\")-1:]\n#         print(s_labl, labl)\n        if (str(s_labl) == str(labl)):\n            obj = new_s[:new_s.find(labl)]\n            actobj = \"(\"+act+ space+ obj.replace(\" \",\"-\")+\")\"\n            goals.append(actobj)\n            break;\n            \ngoals = unduplicate(goals)\n# print(goals)\n\ndef get_goals():\n    g = \"\"\n    for goal in goals:\n        \n        g += goal.lower()+\" \"\n    return(\"(:goal (and \"+g+ \"))\\n\"+\n          \"(:metric minimize (total-cost))\")\n\n\nall_goals = get_goals()\nprint(all_goals)","metadata":{"_uuid":"b1e1afe3-6180-4cde-a62f-585c67737809","_cell_guid":"2726575a-ac23-4fc5-a7cc-537fc05ee937","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#domain file\noperators = get_operators(subsegments)\npredicates = get_predicates(all_preds)\n\ndomainfile = predicates + \"\\n\" + operators + \")\"\nprint(domainfile)","metadata":{"_uuid":"01e0594c-5fdb-451e-b529-a899c97b1608","_cell_guid":"e9380a80-50f9-49d2-9c07-8f04fe581b07","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# files\n#writing to file\nf = open(storyname+\"domain.pddl\", \"w\")\nf.write(domainfile)\nf.close()","metadata":{"_uuid":"686e94a1-c58f-4f83-a023-ad6dd180c074","_cell_guid":"c65b36dd-eea7-42d0-a16c-6cf4d084bfad","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#problem file\nproblemfile = init_objects() + \"\\n\" + initial_state() + \"\\n\" +  all_goals + \")\"\n\nprint(problemfile)","metadata":{"_uuid":"0420e04c-d3d5-4d50-bbb0-5b4bbf46411f","_cell_guid":"e581bece-3fe9-4dc2-8722-966204cb0215","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#writing to file\nf = open(storyname+\"problem.pddl\", \"w\")\nf.write(problemfile)\nf.close()","metadata":{"_uuid":"f50afd6e-0dc0-4a9d-b29c-4dce42242b69","_cell_guid":"edb3ccad-41df-40cb-93c0-24a728761c72","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# complete_effects = []\n# # save the segment number and the pobjs\n# for i, subsegment in enumerate(subsegments):\n#     doc = nlp(subsegment[1])\n\n#     pobjs = []\n#     act_pobjs = []\n#     for token in doc:\n#         if token.dep_ is 'pobj' or token.dep_ is 'dobj':\n#             pobjs.append([token, token.i])\n        \n#     for token in doc:\n#         if token.dep_ is \"nsubj\"and token.text == player_name and token.head.pos is VERB :\n#                 action = token.head\n#                 index = action.i\n#                 get_pobj = [[action, pobj[0]] for pobj in pobjs if index<pobj[1]]\n                \n#                 if(get_pobj):\n#                     act_pobjs.append(get_pobj[0])\n            \n    \n\n\n# # pobjs = pobjs.sort(key=itemgetter(1))\n\n#     if act_pobjs:\n#         complete_effects.append([i, act_pobjs])\n# print(complete_effects)","metadata":{"_uuid":"59575d02-3de1-4b76-87d1-c1f4e1920889","_cell_guid":"01c34e98-6e3e-4795-bf4d-2571e1b54e4c","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"_uuid":"4fecbf44-0435-4209-8cc9-97c2437c7e86","_cell_guid":"b02ce15b-e878-4f6e-b902-8837c9e4e58e","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]}]}